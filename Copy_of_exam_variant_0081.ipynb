{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fortune-max/M4-python-refresher-ml/blob/main/Copy_of_exam_variant_0081.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "721fb5f8",
      "metadata": {
        "id": "721fb5f8"
      },
      "source": [
        "#### Exam task 1:\n",
        "- Download dataset Drug Review Dataset (Druglib.com) from https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29,\n",
        "- load dataset to pandas, column names are present in the dataset\n",
        "- Create target 0/1 variable from effectiveness == Highly Effective.\n",
        "- For all textual features create feature with lenght of string and number of words in it.\n",
        "- draw histograms and distributions for all numeric variables, and store them in .png file\n",
        "- split the dataset to train and test\n",
        "- store yaml file with data on dataset split origins and loading specific"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca2cc33",
      "metadata": {
        "id": "eca2cc33"
      },
      "source": [
        "#### Exam task 2:\n",
        "- Create custom transformer consisting of standardScaler and polynomialTransformer with customizable parameters for all numerical features in the dataset\n",
        "- Create a pipeline with this transformer and LogisticRegression classifier\n",
        "- Create a .py module with custom transformer\n",
        "- Measure quality results on test subsample with metric accuracy and store result in .yaml file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30258e26",
      "metadata": {
        "id": "30258e26"
      },
      "source": [
        "#### Exam task 3:\n",
        "- Create a custom classifier that uses bag of characters 2-grams with PCA to extract data from a textual feature and 'XGBoost's a main classifier\n",
        "- Implement is as a .py module, also implement using .yaml file for setting up bagging parameters min_df, max_df etc. Create a .yaml file for initialization of classifier\n",
        "- Measure quality results on test subsample with metric recall and store result in .yaml file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1290a9a",
      "metadata": {
        "id": "c1290a9a"
      },
      "source": [
        "#### Exam task 4:\n",
        "- Create a custom classifier with pipeline of polynomial feature generation for numeric features, PCA dimensionality reduction and linear regression with parameters of regularization l1\n",
        "- Perform gridSearch for optimal classifier parameters:\n",
        "\n",
        "-- polynomial degree from 5 to 10\n",
        "\n",
        "-- PCA degreee from 15 to 25\n",
        "\n",
        "-- l1 regularization 0.081 to 0.162\n",
        "\n",
        "- Measure quality results on test subsample with metric accuracy and store result in .yaml file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a762d809",
      "metadata": {
        "id": "a762d809"
      },
      "source": [
        "#### Exam task 5*:\n",
        "Perform a free search of best classifier in accuracy metric, save the resulting quality in .yaml, classifier code in .py file and trained classifier in .pkl file. Make sure the result is reproducible, so your classifier can be used and quality results can be confirmed via set of files and descritions you gave\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}